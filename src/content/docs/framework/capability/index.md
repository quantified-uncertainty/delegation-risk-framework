---
title: "Capability Formalization"
sidebar:
  order: 1
---

# Capability Formalization

This section formalizes the **positive side** of the optimization problem: what we're trying to maximize.

$$\text{Capability} = \text{Power} \times \text{Agency}$$

## Pages

| Page | Question |
|------|----------|
| [Agents, Power, and Authority](./agent-power-formalization/) | What makes something an agent? How do we measure power? |
| [Worked Examples](./agency-power-examples/) | What do these metrics look like for real systems? |
| [The Strong Tools Hypothesis](./strong-tools-hypothesis/) | Can we get high capability with low agency? |

## Key Concepts

- **Agency Score**: How well a system's behavior fits a simple utility function (0 = tool, 1 = optimizer)
- **Power Score**: Ability to achieve diverse goals
- **RACAP**: Risk-Adjusted Capability = Capability / Risk

## The Core Insight

We want AI systems that are **maximally capable while minimally risky**. This may be achievable through "strong tools"â€”high power with low agency.

See [The Strong Tools Hypothesis](./strong-tools-hypothesis/) for analysis.
